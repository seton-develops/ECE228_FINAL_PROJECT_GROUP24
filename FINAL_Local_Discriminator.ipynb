{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torchsummary import summary as summary\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909dd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Local_Discriminator2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Local_Discriminator2, self).__init__()\n",
    "        \n",
    "        self.nc = 3\n",
    "        self.ndf = 32\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae514747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Local_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Local_Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 1, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING SAMPLE DATA\n",
    "\n",
    "data_dir = \"C:\\\\Users\\\\Sean\\\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\CELEBA_NOSE\\\\sample\"\n",
    "\n",
    "p =transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder(root = data_dir, transform = p)\n",
    "print(dataset.class_to_idx)\n",
    "\n",
    "idx2class = {v: k for k, v in hotdog_dataset.class_to_idx.items()}\n",
    "print(idx2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db26daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT INTO VALIDATION AND TEST SET USING random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train, valid = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid, batch_size=1024, shuffle=False)\n",
    "\n",
    "#SET OPTIMIZER, CRITERION ETC\n",
    "model = Local_Discriminator2()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.008)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ddc187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAMPLE FOR DATALOADER. NOTE VALIDATION AND TEST NOT INCLUDED\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        print(\"EPOCH \", i)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(inputs)\n",
    "        yhat= torch.flatten(yhat) #IMPORTANT\n",
    "        loss = criterion(yhat, targets.float()) #IMPORTANT\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dl)\n",
    "    print(epoch_loss)\n",
    "    losses.append(epoch_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
