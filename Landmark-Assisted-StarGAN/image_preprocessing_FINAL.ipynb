{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57efa32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@Authors: Sean Tonthat\n",
    "\n",
    "@Description: Helper functions to help clean the code\n",
    "\n",
    "@Date: 6/8/22\n",
    "'''\n",
    "\n",
    "#Import dependencies\n",
    "import cv2\n",
    "import os\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b93848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_to_128_by_128_celebA(image):\n",
    "    '''\n",
    "    Crops input image and resizes to 128x128\n",
    "    \n",
    "    INPUT: \n",
    "        image : (np.array) image from CelebA dataset. Shape is (178x218x3)\n",
    "    \n",
    "    OUTPUT: \n",
    "        crop_image : (np.array) resized and cropped version of the image with shape (128x128x3)\n",
    "    '''\n",
    "    \n",
    "    crop_img = image.copy() #image is 178x218\n",
    "    crop_img = crop_img[20:198, 0:178] #Because height of image is too long we crop\n",
    "    crop_img = cv2.resize(crop_img, (128, 128),interpolation =cv2.INTER_AREA) #resize to 128x128\n",
    "    \n",
    "    return crop_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def trim_to_128_by_128_bitmoji(image):\n",
    "    '''\n",
    "    Crops input image and resizes to 128x128\n",
    "    \n",
    "    INPUT: \n",
    "        image : (np.array) image from Bitmoji dataset. Shape is (384x384x3)\n",
    "    \n",
    "    OUTPUT: \n",
    "        crop_image : (np.array) resized and cropped version of the image with shape (128x128x3)\n",
    "    '''\n",
    "    \n",
    "    crop_img = cv2.resize(image, (128, 128),interpolation =cv2.INTER_AREA)\n",
    "    return crop_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def is_facing_forward(image, coord):\n",
    "    #Takes the uncropped image and outputs a prediction for head pose\n",
    "    '''\n",
    "    INPUT: \n",
    "        image : (np.array) image from CelebA dataset. Shape is (218,178,3)\n",
    "        coord : (list) list of 10 coordinates\n",
    "        eyes have indexes 0-3, nose 4-5, mouth 6-9\n",
    "    \n",
    "    OUTPUT: boolean either FALSE for off-center or TRUE for center\n",
    "    \n",
    "    NOTE: images with prediction left, right will be removed from dataset\n",
    "    \n",
    "    '''\n",
    "    size = image.shape\n",
    " \n",
    "    #This array represents the coordinates in 2D space\n",
    "    points_2D = np.array([\n",
    "                        (coord[4], coord[5]),  # Nose tip\n",
    "                        (coord[0], coord[1]),  # Left eye corner\n",
    "                        (coord[2], coord[3]),  # Right eye corner\n",
    "                        (coord[6], coord[7]),  # Left mouth \n",
    "                        (coord[8], coord[9]),   # Right mouth\n",
    "                        (round((coord[8] + coord[6]) / 2), coord[7] - 20) #chin\n",
    "                      ], dtype=\"double\")\n",
    " \n",
    "\n",
    "    #This array represents the coordinates in 3D space\n",
    "    #This collection of coordinates are commonly used when information regarding the camera are not provided\n",
    "    points_3D = np.array([\n",
    "                      (0.0, 0.0, 0.0),         #Nose tip\n",
    "                      (-225.0, 170.0, -135.0), #Left eye corner\n",
    "                      (225.0, 170.0, -135.0),  #Right eye corner \n",
    "                      (-150.0, -150.0, -125.0),#Left mouth \n",
    "                      (150.0, -150.0, -125.0),  #Right mouth \n",
    "                      (0.0, -330.0, -65.0) #chin\n",
    "                     ])\n",
    "    \n",
    "    \n",
    "    #Get the coordinates in 3d space for the nose and project a point (0.0, 0.0, 1000.0) into 3D space\n",
    "    dim = size[1]\n",
    "    midpoint = (size[1] * 0.5, size[0] * 0.5)\n",
    "    camera_matrix = np.array([[dim, 0, center[0]],[0, focal_length, midpoint[1]],[0, 0, 1]], dtype = \"double\")\n",
    "    \n",
    "    _, rotation_vector, translation_vector = cv2.solvePnP(points_3D, points_2D, camera_matrix, np.zeros((4,1)) , flags=0)\n",
    "    nose_end_point2D, _ = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    \n",
    "    #Get the angle between the projected point and the nose matrix\n",
    "    point1 = ( int(points_2D[0][0]), int(points_2D[0][1]))\n",
    "    point2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "\n",
    "    inner = np.inner(point1, point2)\n",
    "    norms = LA.norm(point1) * LA.norm(point2)\n",
    "\n",
    "    cos = inner / norms\n",
    "    rad = np.arccos(np.clip(cos, -1.0, 1.0))\n",
    "    head_pose_angle = np.rad2deg(rad)\n",
    "    \n",
    "    \n",
    "    #If false is returned then the image has a non-forward facing image\n",
    "    if (abs(head_pose_angle) > 1.2):\n",
    "        return False\n",
    "    \n",
    "\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e69aa99",
   "metadata": {},
   "source": [
    "# Cleaning Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d169e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV contains landmark coordinates of mouth, eyes, nose for celebA dataset\n",
    "dir_att = \"C:\\\\Users\\\\Sean\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\img_align_celeba_unaltered\\\\list_landmarks_align_celeba.txt\"\n",
    "data_att = pd.read_csv(dir_att, delim_whitespace=True)\n",
    "df_list = data_att.values.tolist() #collect csv file onto list for iterating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967ed1ea",
   "metadata": {},
   "source": [
    "## Stage 1: Remove non-forward facing images from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7eabab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell does the following:\n",
    "\n",
    "1) reads image in a directory (presumably the celebA dataset images)\n",
    "2) checks if images have subjects facing forward using is_facing_forward()\n",
    "3) if image is facing foward then add it to a new directory\n",
    "4) append the coordinates of the image onto an excel file\n",
    "'''\n",
    "\n",
    "# assign directory\n",
    "src_img_dir = \"C:\\\\Users\\\\Sean\\\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\img_align_celeba_unaltered\\\\img_align_celeba\"\n",
    "tgt_img_dir = \"C:\\\\Users\\\\Sean\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\img_align_celeba_ALTERED\\\\img_celebA\\\\\"\n",
    "\n",
    "\n",
    "# create an excel worksheet to store the landmarks of the front only dataset, it omits non-frontal images\n",
    "wb_path = \"C:\\\\Users\\\\Sean\\\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\img_align_celeba_ALTERED\\\\celebA_landmarks_front_only.xlsx\"\n",
    "wb = openpyxl.load_workbook(filename = wb_path)\n",
    "sheet = wb[\"DATA\"] #set active sheet to a pre-existing sheet named \"DATA\" in the excel workbook\n",
    "\n",
    "\n",
    "print(\"STARTING\")\n",
    "\n",
    "\n",
    "for i, filename in enumerate(os.scandir(src_img_dir)):\n",
    "    \n",
    "    if filename.is_file():\n",
    "        coord = df_list[i][1:]\n",
    "        image = mpimg.imread(filename.path)\n",
    "        \n",
    "        if is_facing_forward(image, coord): #image is facing forward, else ignore\n",
    "            \n",
    "            #WRITE landmarks/ ATTRIBUTES to excel file\n",
    "            sheet.append(df_list[i]) #append landmarks\n",
    "            \n",
    "            #COPY file to target directory\n",
    "            tgt = tgt_img_dir + df_list[i][0]\n",
    "            copyfile(filename.path, tgt)\n",
    "            \n",
    "\n",
    "wb.save(wb_path)\n",
    "wb.close()   \n",
    "\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c2520",
   "metadata": {},
   "source": [
    "## Stage 2: Resize the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba29d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE HERE\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Read excel file in earlier stage 1\n",
    "Convert it to a list. The list will contain the coordinates of the forward facing images\n",
    "'''\n",
    "\n",
    "crop_tgt_dir =  \"C:\\\\Users\\\\Sean\\\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\img_aligned_cropped\\\\\"\n",
    "tgt_img_dir = \"C:\\\\Users\\\\Sean\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\img_align_celeba_ALTERED\\\\img_celebA\"\n",
    "\n",
    "#CSV contains landmark coordinates of mouth, eyes, nose for celebA dataset\n",
    "dir_att = \"C:\\\\Users\\\\Sean\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\img_align_celeba_ALTERED\\\\celebA_landmarks_front_only.xlsx\"\n",
    "data_att = pd.read_excel(dir_att)\n",
    "df_list = data_att.values.tolist()\n",
    "\n",
    "print(\"DONE HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "101bf9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING\n",
      "['000007.jpg', 70, 112, 108, 111, 85, 135, 72, 152, 104, 152]\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "read all the files in tgt_img_dir\n",
    "crop and resize each image to 128x128 using trim_to_128_by_128()\n",
    "'''\n",
    "\n",
    "print(\"STARTING\")\n",
    "print(df_list[0])\n",
    "for i, filename in enumerate(os.scandir(tgt_img_dir)):\n",
    "    if filename.is_file():\n",
    "        image = cv2.imread(filename.path)\n",
    "        crop_img = trim_to_128_by_128(image) #crop image\n",
    "        filename = crop_tgt_dir + df_list[i][0]\n",
    "        cv2.imwrite(filename, crop_img) #save image to directory\n",
    "        \n",
    "\n",
    "        \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c628a",
   "metadata": {},
   "source": [
    "## Stage 3: Resize the Bitmoji Images to 128x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ec2fdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE HERE\n"
     ]
    }
   ],
   "source": [
    "orig_bitmoji_dir =  \"C:\\\\Users\\\\Sean\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\bitmoji\\\\BitmojiDataset\\\\images\"\n",
    "tgt_bitmoji_dir =\"C:\\\\Users\\\\Sean\\\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\bitmoji\\\\BitmojiDataset\\\\images_resized\\\\\"\n",
    "\n",
    "#CSV contains landmark coordinates of mouth, eyes, nose for celebA dataset\n",
    "dir_att = \"C:\\\\Users\\\\Sean\\Desktop\\\\UCSD Courses\\\\ECE228 Project\\\\bitmoji\\\\BitmojiDataset\\\\landmarks.xlsx\"\n",
    "data_att = pd.read_excel(dir_att)\n",
    "df_list = data_att.values.tolist()\n",
    "\n",
    "print(\"DONE HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda1b796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "read all the files in tgt_img_dir\n",
    "crop and resize each image to 128x128 using trim_to_128_by_128_bitmoji()\n",
    "'''\n",
    "\n",
    "print(\"STARTING\")\n",
    "print(df_list[0])\n",
    "for i, filename in enumerate(os.scandir(orig_bitmoji_dir)):\n",
    "    if filename.is_file():\n",
    "        image = cv2.imread(filename.path)\n",
    "        crop_img = trim_to_128_by_128_bitmoji(image) #crop image\n",
    "        filename = tgt_bitmoji_dir + df_list[i][0]\n",
    "        cv2.imwrite(filename, crop_img) #save image to directory\n",
    "        \n",
    "\n",
    "        \n",
    "print(\"DONE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
